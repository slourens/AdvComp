{
    "contents" : "## Script for longitudinal analysis of O'Donnell EEG data - NAC study\n## Date: 2016/11/11\n\n## dplyr library for slicker data manipulation - install with install.packages(\"dplyr\")\nlibrary(dplyr)\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(multcomp)\nlibrary(psych)\n\n## Specify locations to write baseline comparison results/longitudinal comparison results\nBaselineResultsFileLocation = \"\"\nLongitudinalResultsFileLocation = \"\"\n\n## Reading in data files\ndfAlpha <- read.csv(\"/Users/spencerlourens/Desktop/Work/NAC/EEGAnalysisODonnell/NAC_alphaEEG_final.csv\", encoding = \"UCS-2LE\")\ndfDelta <- read.csv(\"/Users/spencerlourens/Desktop/Work/NAC/EEGAnalysisODonnell/NAC_deltaEEG_final.csv\", encoding = \"UCS-2LE\")\ndfGamma <- read.csv(\"/Users/spencerlourens/Desktop/Work/NAC/EEGAnalysisODonnell/NAC_gammaEEG_final.csv\", encoding = \"UCS-2LE\")\ndfTheta <- read.csv(\"/Users/spencerlourens/Desktop/Work/NAC/EEGAnalysisODonnell/NAC_thetaEEG_final.csv\", encoding = \"UCS-2LE\")\n\n## Fix #NULL! to make NA\ndfAlpha[dfAlpha==\"#NULL!\"] <- NA\ndfDelta[dfDelta==\"#NULL!\"] <- NA\ndfGamma[dfGamma==\"#NULL!\"] <- NA\ndfTheta[dfTheta==\"#NULL!\"] <- NA\n\n## Remove _eegcl from ID variable, and rename it\n## Remove File_A column\n## Gather data into 'long' form, create visit column\n\n\n## Alpha\ndfAlpha <- dfAlpha %>% gather(\"visit\", \"alpha\", AlphaOzPz2:AlphaOzPz16) %>%\n\n  mutate(CharFile = as.character(File)) %>% separate(CharFile, into = c(\"ID\", \"extra\"), sep = \"_\") %>%\n\n  mutate(visit = ifelse(visit == \"AlphaOzPz2\", 2, ifelse(visit == \"AlphaOzPz9\", 9, 16))) %>%\n\n  select(ID, visit, alpha) %>% arrange(ID, visit)\n\n## Delta\ndfDelta <- dfDelta %>% gather(\"visit\", \"delta\", DeltaMid2:DeltaMid16) %>%\n\n  mutate(CharFile = as.character(File)) %>% separate(CharFile, into = c(\"ID\", \"extra\"), sep = \"_\") %>%\n\n  mutate(visit = ifelse(visit == \"DeltaMid2\", 2, ifelse(visit == \"DeltaMid9\", 9, 16))) %>%\n\n  select(ID, visit, delta) %>% arrange(ID, visit)\n\n## Gamma\ndfGamma <- dfGamma %>% gather(\"visit\", \"gamma\", GammaMid2:GammaMid16) %>%\n\n  mutate(CharFile = as.character(File)) %>% separate(CharFile, into = c(\"ID\", \"extra\"), sep = \"_\") %>%\n\n  mutate(visit = ifelse(visit == \"GammaMid2\", 2, ifelse(visit == \"GammaMid9\", 9, 16))) %>%\n\n  select(ID, visit, gamma) %>% arrange(ID, visit)\n\n## Theta\ndfTheta <- dfTheta %>% gather(\"visit\", \"theta\", ThetaMid2:ThetaMid16) %>%\n\n  mutate(CharFile = as.character(File)) %>% separate(CharFile, into = c(\"ID\", \"extra\"), sep = \"_\") %>%\n\n  mutate(visit = ifelse(visit == \"ThetaMid2\", 2, ifelse(visit == \"ThetaMid9\", 9, 16))) %>%\n\n  select(ID, visit, theta) %>% arrange(ID, visit)\n\n\n## merge datasets together\ndfFull <- full_join(dfAlpha, dfDelta, by = c(\"ID\", \"visit\"))\ndfFull <- full_join(dfFull, dfGamma, by = c(\"ID\", \"visit\"))\ndfFull <- full_join(dfFull, dfTheta, by = c(\"ID\", \"visit\"))\n\n## Remove individual with ID == N2011 (non-compliance) and N2017 (not treated)\n\ndf <- dfFull %>% filter(ID != \"N2011\" & ID != \"N2017\" & ID != \"N2021\")\n\n## Calculate number of observations per person\n## df <- df %>% group_by(subject) %>% mutate(ni = n())\n\n## Calculate baseline values for each outcome\n## Tom - This should automatically adjust to any number of columns you put into the input dataset.\n## The last column is made to be scanner because it's the last defined column, so I set the analysis variable list to exlude it\n## with length(names(df)) - 1\n## If the beginning of your file input is changed, then you will have to change the 10 below so that it coincides\nvarsToAnalyze <- names(df)[10:(length(names(df))-1)]\n\ndfSplit <- split(df, df$subject)\n\n## Deal with 6 mo and 12 mo completer analyses at once\n## Variable compMods is short for completer model analysis (6 and 12 month)\n## Adjust for baseline outcome value in all models\n## currLM6 is 6 mo completer model\n## currLM12 is 12 mo completer model\ncompMods <- lapply(varsToAnalyze, function(t) {\n  dfSplit <- lapply(dfSplit, function(v) {\n      newVar <- paste(t, \"1\", sep = \"\")\n      if (length(v[,t]) == 1)\n      {\n        v[newVar] <- v[,t]\n      } else {\n        v[newVar] <- rep(v[1,t], dim(v)[1])\n      }\n      return(v)\n  })\n  df <- do.call('rbind', dfSplit)\n  ## Define 6 mo completer and 12 mo completer datasets\n  vis6mo = df[df$scan == 2,]\n  vis12mo = df[df$scan == 3,]\n  currForm <- as.formula(paste(t, \"~ \", t, \"1\", \" + nac_group + factor(scanner)\", sep = \"\"))\n  currLM6 <- lm(currForm, data = vis6mo)\n  currLM12 <- lm(currForm, data = vis12mo)\n  lm6Coeff <- summary(currLM6)$coefficients\n  lm6Sigma <- summary(currLM6)$sigma\n  diffEstlm6 <- lm6Coeff[3,1]\n  effSizelm6 <- diffEstlm6 / lm6Sigma\n  tVallm6 <- lm6Coeff[3,3]\n  pVallm6 <- lm6Coeff[3,4]\n  lm12Coeff <- summary(currLM12)$coefficients\n  lm12Sigma <- summary(currLM12)$sigma\n  diffEstlm12 <- lm12Coeff[3,1]\n  effSizelm12 <- diffEstlm12 / lm12Sigma\n  tVallm12 <- lm12Coeff[3,3]\n  pVallm12 <- lm12Coeff[3,4]\n  ## put it all into a table, 6 mo and 12 mo on subsequent rows\n  m6Row <- c(diffEstlm6, tVallm6, pVallm6, effSizelm6)\n  m12Row <- c(diffEstlm12, tVallm12, pVallm12, effSizelm12)\n  tempDat <- data.frame(rbind(m6Row, m12Row))\n  names(tempDat) <- c(\"Mean difference\", \"t-value\", \"p-value\", \"Effect Size estimate\")\n  tempDat$Model <- c(\"6 Month Completers\", \"12 Month Completers\")\n  tempDat$Variable <- c(t, t)\n  rownames(tempDat) <- NULL\n  tempDat <- tempDat[,c(\"Variable\", \"Model\", \"Mean difference\", \"t-value\", \"p-value\", \"Effect Size estimate\")]\n  return(tempDat)\n})\n\n## Now you get one table with 6 and 12 month completion analysis, estimated mean differences at 6 and 12 months, t and p-values, and effect size estimates\n## The effect size estimates are in the form (mu_1 - mu_2) / SD, so cohen's D form that you are most likely familiar with\ncompModsDF <- do.call('rbind', compMods)\n\n## Write these results to csv file\nwrite.csv(compModDF, file = TomHummerBaselineResultsFileLocation)\n\n## Assessment of scanner differences by group, missing data by group\n\n## 21.2 % skyra, 1.5 % prisma, 77.3 % trio\npropCalc <- prop.table(table(df$scanner))\n\n## Test whether scanner varies by group\ntblScanner <- table(df$scanner, df$nac_group)\nscannerTest <- chisq.test(tblScanner) ## p = 1 - no difference\n## No evidence that scanner differences exist by group so is not affecting final results\n\n## Big issue is scanner changing from visit to visit - let's assess\ndatSplit <- split(df, df$parc_id)\n\nscannerFlag <- unlist(lapply(datSplit, function(t) {\n\n  flag <- 0\n  baseline <- t$scanner[1]\n  if (length(t$scanner) > 1) {\n    for (i in 2:length(t$scanner)) {\n      if (t$scanner[i] != baseline) {\n        flag <- 1\n      }\n    }\n  }\n  return(flag)\n}))\n\n\n## Look at N2051, N2052, N2061, N2063\ndfDiffScan <- df %>% filter(parc_id %in% c(\"N2051\", \"N2052\", \"N2061\", \"N2062\"))\n\n## Assess missing data\ndfBase <- df %>% filter(scan == 1)\n\n## Arm A: 30% drop-out by 6 mo, 45% drop-out by 1 year, 55% completion\n## Arm B: 33% drop-out by 6 mo, 43% drop-out by 1 year, 57% completion\ntblFup <- table(dfBase$ni, dfBase$nac_group)\nchisq.test(tblFup)\n## R warns that chisq test may be inappropriate\nfisher.test(tblFup)\n\n## scanner was not imbalanced by treatment group - go ahead with modeling not adjusting for scanner as a fixed effect\nlmExample1 <- lmer(lh_frontalpole_thickness ~ age + factor(scan) + factor(scanner) + nac_group + factor(scan) * nac_group + (1 | subject), data = df)\n\n## Table which holds estimated effects, standard error estimates, df, t-values, and p-values\ntests <- summary(lmExample1)$coefficients\n\n\nlmmList <- lapply(varsToAnalyze, function(t) {\n  ## Fixed-effects adjustments for age (at baseline), scan (visit), treament, their interaction\n  ## Random-effects for subject, modeling correlation due to repeated measurements on subject\n  formulaLMM4 <- paste(t, \" ~ age + factor(scanner) + factor(scan) * nac_group + (1 | subject)\", sep = \"\")\n  formulaLMM3 <- paste(t, \" ~ age + factor(scanner) + factor(scan) + nac_group + (1 | subject)\", sep = \"\")\n  formulaLMM2 <- paste(t, \" ~ age + factor(scanner) + nac_group + (1 | subject)\", sep = \"\")\n  formulaLMM1 <- paste(t, \" ~ age + factor(scanner) + factor(scan) + (1 | subject)\", sep = \"\")\n  currLMM4 <- lmer(formulaLMM4, data = df, REML = F)\n  currLMM3 <- lmer(formulaLMM3, data = df, REML = F)\n  currLMM2 <- lmer(formulaLMM2, data = df, REML = F)\n  currLMM1 <- lmer(formulaLMM1, data = df, REML = F)\n\n  testLMM <- summary(currLMM)$coefficients\n  anova1 <- suppressWarnings(anova(currLMM2, currLMM3)) ## adding visit with group already in model\n  anova2 <- suppressWarnings(anova(currLMM1, currLMM3)) ## adding group with visit already in model\n  anova3 <- suppressWarnings(anova(currLMM3, currLMM4)) ## adding group * visit with both group and visit already in model\n  ## Collect p-values\n  ## Compare model with visit to one without\n  ## Compare model with anova to one with visit only\n  ## Compare model with interaction to one with both main effects\n  anova1p <- anova1$`Pr(>Chisq)`[2]\n  anova1CSq <- anova1$Chisq[2]\n  anova2p <- anova2$`Pr(>Chisq)`[2]\n  anova2CSq <- anova2$Chisq[2]\n  anova3p <- anova3$`Pr(>Chisq)`[2]\n  anova3CSq <- anova3$Chisq[2]\n  currRow <- c(anova1p, anova1CSq, anova2p, anova2CSq, anova3p, anova3CSq)\n  currRowDat <- data.frame(t(currRow))\n  currRowDat$Variable <- t\n  names(currRowDat) <- c(\"Visit p-value\", \"Visit ChiSq\", \"Treatment p-value\", \"Treatment ChiSq\", \"Treatment * Visit p-value\", \"Treatment * visit ChiSq\", \"Variable\")\n  currRowDat <- currRowDat[,c(\"Variable\", \"Visit p-value\", \"Visit ChiSq\", \"Treatment p-value\", \"Treatment ChiSq\", \"Treatment * Visit p-value\", \"Treatment * visit ChiSq\")]\n  return(currRowDat)\n})\n\n## Results from relevant likelihood ratio tests (LRTs) looking at importance of effects (visit, Treatment, or visit * Treatment)\n## Notice that\nlmmLRTDF <- do.call('rbind', lmmList)\n\n## Effects do not seem important here - smallest p-value in any analysis is approx 0.02....\n## followed by 0.064, 0.081... would expect more significant findings at 0.05 by random chance....\n\n\n## Write lmmDF to a csv\nwrite.csv(lmmLRTDF, file = TomHummerLongitudinalResultsFileLocation)\n\n\n\n\n",
    "created" : 1478877196667.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2795232375",
    "id" : "CEFD9546",
    "lastKnownWriteTime" : 1478883957,
    "path" : "~/Desktop/Work/NAC/EEGAnalysisODonnell/EEGAnalysisScript20161111.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "type" : "r_source"
}